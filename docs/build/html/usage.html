
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Usage &#8212; LCD for CT Toolbox 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API" href="api.html" />
    <link rel="prev" title="Welcome to LCD for CT Toolbox’s documentation!" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Permalink to this heading">¶</a></h1>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this heading">¶</a></h2>
<p>Since the introduction of non-linear iterative CT reconstruction and image processing devices (FDA product code JAX) low contrast detectability has been an essential measure of image quality. This is because many of these non-linear image reconstruction and enhancement devices make assumptions about local-smoothness which determines where the algorithm denoises more aggresively. As smoothness is commonly measured mathematically as local gradients, this causes many of these noise reduction algorithms to perform better in high contrast regions but poorly in low contrast. However, low contrast lesions are the most difficult to detect by human readers as they are most easily obscured by noise. Furthermore such low contrast lesions are clinically significant so it is thus crucial to ensure that any image enhancement software applied to the image does not mistake low contrast lesions as noise and remove them. For these reasons low contrast detectability has been an invaluable component to medical image evaluations to ensure that the clinical utility of the image has not been impaired.</p>
<p>Measurement of low contrast detectability can be done in various ways. Human reader studies of detectability are the oldest method and often considered as a reference point to other measures of detectability. In human reader studies, human readers are given a series of images and report whether a signal is either present or absent (See Figure 1 for an example). However, given the difficulty of performing human reader studies when doing a parameter optimization of an image processing algorithm, model observers can be used to programatically assess the detectability of an object of interest in an image.</p>
<img alt="_images/signal_example.png" src="_images/signal_example.png" />
<p>For this ease of use, model observers are routinely used by image processing device sponsors to support their device dose reduction or image quality claims. However,</p>
<p>There are many types of model observers, some are designed to mimic human performance and act as surragates to human readers while others outperform human readers and can be used as a measure of the inherent information in an image. With</p>
<div class="highlight-matlab notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">sa_train</span><span class="p">,</span><span class="w"> </span><span class="n">sa_test</span><span class="p">,</span><span class="w"> </span><span class="n">sp_train</span><span class="p">,</span><span class="w"> </span><span class="n">sp_test</span><span class="p">]</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">train_test_split</span><span class="p">(</span><span class="n">sa_imgs</span><span class="p">,</span><span class="w"> </span><span class="n">sp_imgs</span><span class="p">);</span>
<span class="hll"><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">observer</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">DOG_CHO_2D</span><span class="p">();</span>
</span><span class="hll"><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">dog_res</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">observer</span><span class="p">.</span><span class="n">perform_study</span><span class="p">(</span><span class="n">sa_train</span><span class="p">,</span><span class="w"> </span><span class="n">sp_train</span><span class="p">,</span><span class="w"> </span><span class="n">sa_test</span><span class="p">,</span><span class="w"> </span><span class="n">sp_test</span><span class="p">);</span>
</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="nb">fprintf</span><span class="p">(</span><span class="s">&#39;DOG CHO auc: %f\n&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">dog_res</span><span class="p">.</span><span class="n">auc</span><span class="p">)</span>
<span class="n">DOG</span><span class="w"> </span><span class="s">CHO</span><span class="w"> </span><span class="s">auc:</span><span class="w"> </span><span class="s">0.800000</span>
</pre></div>
</div>
</section>
<section id="images-from-a-directory">
<h2>0. Images from a Directory<a class="headerlink" href="#images-from-a-directory" title="Permalink to this heading">¶</a></h2>
<p>demo_00_images_from_directory.m</p>
<ul class="simple">
<li><p>demonstrates basics of loading signal-absent and signal-present image series in a 3D array to run a single model-observer study using provided small dataset</p></li>
<li><p>This script also demonstrates how to load up multiple different types of Model Observer</p></li>
</ul>
</section>
<section id="repeated-studies">
<h2>1. Repeated Studies<a class="headerlink" href="#repeated-studies" title="Permalink to this heading">¶</a></h2>
<p>demo_01_repeat_studies.m</p>
<ul class="simple">
<li><p>builds upon [demo_00](demo_00_images_from_directory.m) by demonstrating how to perform repeat studies to get a uncertainty estimates and export results to a csv file</p></li>
</ul>
</section>
<section id="multiple-dose-levels">
<h2>2. Multiple Dose Levels<a class="headerlink" href="#multiple-dose-levels" title="Permalink to this heading">¶</a></h2>
<p>demo_02_multiple_dose_levels.m</p>
<ul class="simple">
<li><p>builds upon [demo_01](demo_01_repeat_studies.m) by demonstrating how to perform repeat studies at multiple dose levels to get detectability (e.g. auc or snr) as a function of dose level for multiple different observers</p></li>
</ul>
</section>
<section id="accessing-a-large-dataset">
<h2>3. Accessing a large dataset<a class="headerlink" href="#accessing-a-large-dataset" title="Permalink to this heading">¶</a></h2>
<p>demo_03_access_large_dataset.m</p>
<ul class="simple">
<li><p>builds upon [demo_02](demo_02_multiple_dose_levels.m) by demonstrating how to perform repeat studies at multiple dose levels to get detectability (e.g. auc or snr) as a function of dose level for multiple different observers</p></li>
<li><p>The large dataset used can be downloaded here:</p></li>
</ul>
<a class="reference external image-reference" href="https://doi.org/10.5072/zenodo.1150650"><img alt="https://sandbox.zenodo.org/badge/DOI/10.5072/zenodo.1150650.svg" src="https://sandbox.zenodo.org/badge/DOI/10.5072/zenodo.1150650.svg" /></a>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">LCD for CT Toolbox</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#motivation">Motivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#images-from-a-directory">0. Images from a Directory</a></li>
<li class="toctree-l2"><a class="reference internal" href="#repeated-studies">1. Repeated Studies</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multiple-dose-levels">2. Multiple Dose Levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="#accessing-a-large-dataset">3. Accessing a large dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Welcome to LCD for CT Toolbox’s documentation!</a></li>
      <li>Next: <a href="api.html" title="next chapter">API</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Brandon Nelson, Rongping Zeng.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/usage.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>